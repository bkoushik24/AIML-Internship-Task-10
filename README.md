# AIML-Internship-Task-10
K-Nearest Neighbors (KNN) implementation for handwritten digit classification using the Sklearn Digits dataset, including hyperparameter tuning, confusion matrix analysis, and accuracy comparison.
âœï¸ Handwritten Digit Classification using KNN
ğŸ“Œ Project Overview

This project implements a K-Nearest Neighbors (KNN) classifier to recognize handwritten digits (0â€“9) using the Sklearn Digits dataset. The objective is to classify grayscale 8x8 pixel digit images into their respective numerical labels.

The project demonstrates how distance-based learning works and how selecting the correct value of K impacts model performance.

ğŸ“Š Dataset Information

Dataset: Sklearn Digits Dataset

Total Samples: 1797

Features: 64 (8x8 pixel flattened image)

Target Classes: 10 (Digits 0â€“9)

Each image is:

8x8 grayscale

Converted into 64 numerical pixel values

âš™ï¸ Technologies Used

Python

NumPy

Matplotlib

Scikit-learn

ğŸ”„ Project Workflow

1ï¸âƒ£ Load dataset using load_digits()
2ï¸âƒ£ Explore dataset shape and structure
3ï¸âƒ£ Visualize sample digit images
4ï¸âƒ£ Split dataset into training and testing sets
5ï¸âƒ£ Apply feature scaling using StandardScaler
6ï¸âƒ£ Train KNN model with K=3
7ï¸âƒ£ Experiment with multiple K values (3, 5, 7, 9)
8ï¸âƒ£ Plot Accuracy vs K graph
9ï¸âƒ£ Generate confusion matrix
ğŸ”Ÿ Display predicted test images

ğŸ“ˆ Model Optimization

Different values of K were tested:

K = 3

K = 5

K = 7

K = 9

An Accuracy vs K graph was plotted to select the best-performing value.

ğŸ¯ Key Learnings

Importance of feature scaling in distance-based models

Effect of K value on bias-variance tradeoff

How KNN performs multi-class classification

Interpreting confusion matrix for misclassified digits

Visualizing image classification results
